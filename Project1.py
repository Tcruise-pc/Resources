#import
import tensorflow as tf

#Load dataset
mnist = tf.keras.datasets.mnist
(x_train, y_train),(x_test, y_test) = mnist.load_data()

#How data looks
print(x_train[14])

#Visualization

import matplotlib.pyplot as plt

plt.imshow(x_train[8],cmap=plt.cm.binary)
plt.show()

print(y_train[8])

#Normalization
x_train = tf.keras.utils.normalize(x_train, axis=1)
x_test = tf.keras.utils.normalize(x_test, axis=1)

x_train[6]

print(x_train[10])

plt.imshow(x_train[10],cmap=plt.cm.binary)
plt.show()

#Build a Model
model = tf.keras.models.Sequential()

#So flatten them to 1*784
model.add(tf.keras.layers.Flatten())

#Adding Layers
model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))

#Adding More layers
model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))

#Adding More layers
model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))

#Adding Output layer
model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))

#Train the model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.fit(x_train, y_train, epochs=9)

val_loss, val_acc = model.evaluate(x_test, y_test)
print(val_loss)
print(val_acc)

#To save the model
model.save('digitDemo.model')

#Load it back
new_model = tf.keras.models.load_model('digitDemo.model')

predictions = new_model.predict(x_test)
print(predictions)

import numpy as np
predictions = [1,2,3]
print(np.argmax(predictions[2]))

plt.imshow(x_test[2],cmap=plt.cm.binary)
plt.show()


""" OUtput  2022-04-10 17:51:26.264043: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2022-04-10 17:51:26.264267: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   1 168 242  28   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0  10 228 254 100   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0 190 254 122   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  83 254 162   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  29 254 248  25   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  29 255 254 103   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  29 254 254 109   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  29 254 254 109   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  29 254 254 109   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  29 255 254 109   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  29 254 254 109   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  29 254 254  63   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  29 254 254  28   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  29 254 254  28   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  29 254 254  35   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  29 254 254 109   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   6 212 254 109   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0 203 254 178   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0 155 254 190   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0  32 199 104   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]]
1
[[0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.06923363
  0.14712657 0.24945318 0.1796561  0.12228485 0.11590366 0.0062582
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.26784526 0.3989176
  0.31669617 0.28932012 0.27489548 0.26322332 0.24948754 0.06884022
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.04680791 0.3824334
  0.31669617 0.28932012 0.27489548 0.26322332 0.24948754 0.248242
  0.13760186 0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.17143566
  0.30422781 0.28932012 0.24242751 0.26322332 0.24948754 0.26493053
  0.27716945 0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.25809491 0.28932012 0.22727579 0.26322332 0.24948754 0.26493053
  0.06683519 0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.10473417 0.23464545 0.27489548 0.26322332 0.24948754 0.26493053
  0.08059537 0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.02733733 0.22619352 0.26322332 0.24948754 0.26493053
  0.33614168 0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.11346201 0.15605062 0.27381321 0.26322332 0.24948754 0.26493053
  0.22016297 0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.10401758 0.35276184
  0.31170883 0.28932012 0.27489548 0.26322332 0.24948754 0.26493053
  0.06683519 0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.2106356  0.4071597
  0.31669617 0.28932012 0.27489548 0.26322332 0.24948754 0.26493053
  0.28699816 0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.18132618
  0.30672148 0.28932012 0.27489548 0.26322332 0.24948754 0.26493053
  0.33614168 0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.09101898 0.10137595 0.09632164 0.09637704 0.23573625 0.26493053
  0.33614168 0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.00103631 0.125726   0.26493053
  0.43049724 0.74210264 0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.00725419 0.24948754 0.26493053
  0.42066853 0.67028626 0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.14301109 0.24948754 0.26493053
  0.22802593 0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.10878298 0.45066626 0.24969673 0.         0.         0.
  0.         0.         0.02705664 0.24871495 0.24948754 0.26493053
  0.06683519 0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.93896892 0.64671882 0.59649775 0.1644903  0.09361582 0.
  0.0635886  0.10137595 0.22294673 0.26322332 0.24948754 0.14498167
  0.01572593 0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.32634895 0.50158901 0.70469967 0.66318312 0.57729756 0.29671557
  0.30048731 0.28932012 0.27489548 0.26218701 0.20921593 0.01147337
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.35645919 0.29131286 0.66318312 0.66051162 0.41869864
  0.31669617 0.28932012 0.27489548 0.2445697  0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.01942086 0.30548199 0.30425142 0.27198927
  0.31669617 0.28932012 0.25866149 0.05181561 0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.        ]]
2022-04-10 17:52:38.742955: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found
2022-04-10 17:52:38.743523: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2022-04-10 17:52:38.775136: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: LP-5CD013FQNG
2022-04-10 17:52:38.776333: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: LP-5CD013FQNG
2022-04-10 17:52:38.777107: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with 
oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Epoch 1/9
1875/1875 [==============================] - 12s 6ms/step - loss: 0.2491 - accuracy: 0.9233
Epoch 2/9
1875/1875 [==============================] - 10s 6ms/step - loss: 0.1039 - accuracy: 0.9678
Epoch 3/9
1875/1875 [==============================] - 8s 4ms/step - loss: 0.0724 - accuracy: 0.9771
Epoch 4/9
1875/1875 [==============================] - 9s 5ms/step - loss: 0.0555 - accuracy: 0.9820
Epoch 5/9
1875/1875 [==============================] - 6s 3ms/step - loss: 0.0453 - accuracy: 0.9852
Epoch 6/9
1875/1875 [==============================] - 5s 3ms/step - loss: 0.0339 - accuracy: 0.9893
Epoch 7/9
1875/1875 [==============================] - 5s 3ms/step - loss: 0.0298 - accuracy: 0.9900
Epoch 8/9
1875/1875 [==============================] - 8s 5ms/step - loss: 0.0273 - accuracy: 0.9909
Epoch 9/9
1875/1875 [==============================] - 11s 6ms/step - loss: 0.0217 - accuracy: 0.9929
313/313 [==============================] - 1s 3ms/step - loss: 0.1026 - accuracy: 0.9743
0.10264487564563751
0.9743000268936157
2022-04-10 17:53:55.218383: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
[[2.3568737e-11 1.7593096e-09 5.3981237e-09 ... 9.9999988e-01
  2.3041319e-10 1.5043926e-07]
 [4.6783848e-16 2.2881316e-08 1.0000000e+00 ... 1.8449395e-10
  5.4516001e-12 6.8937079e-18]
 [1.0828452e-08 9.9995470e-01 1.5083859e-07 ... 3.9620376e-05
  1.7732740e-06 4.8148323e-08]
 ...
 [4.6101317e-13 3.5243607e-11 3.3630324e-11 ... 8.2071200e-10
  2.5248892e-11 9.8377733e-09]
 [3.4284085e-14 1.2855496e-15 4.5344161e-14 ... 2.0411990e-11
  2.4988720e-09 2.5510898e-13]
 [7.4695317e-10 7.8852229e-12 5.4297864e-12 ... 3.0095509e-12
  4.3717425e-09 8.5415930e-10]]
0 """